<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Codeblaze.SemanticKernel.Connectors.Ollama</name>
    </assembly>
    <members>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion.OllamaChatRequestMessage.Role">
            <summary>
            The role of the author of the message either "system", "user", or "assistant".
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion.OllamaChatRequestMessage.Content">
             <summary>
            The content of the message
             </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion.OllamaChatResponseMessageContent.Role">
            <summary>
            The role of the author of the message either "system", "user", or "assistant".
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion.OllamaChatResponseMessageContent.Content">
            <summary>
            The message content
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion.OllamaChatResponseMessage.Message">
            <summary>
            The message generated by the chat model.
            </summary>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaBase`1.PingOllamaAsync(System.Threading.CancellationToken)">
            <summary>
            Ping Ollama instance to check if the required llm model is available at the instance
            </summary>
            <param name="cancellationToken"></param>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaTextGeneration(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.String,System.String)">
            <summary>
            Adds Ollama as the text generation llm backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaTextGeneration(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.Uri,System.String)">
            <summary>
            Adds Ollama as the text generation llm backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaChatCompletion(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.String,System.String)">
            <summary>
            Adds Ollama as the chat completion llm backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaChatCompletion(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.Uri,System.String)">
            <summary>
            Adds Ollama as the chat completion llm backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaTextEmbeddingGeneration(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.String,System.String)">
            <summary>
            Adds Ollama as the text embedding generation backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaKernelBuilderExtensions.AddOllamaTextEmbeddingGeneration(Microsoft.SemanticKernel.IKernelBuilder,System.String,System.Uri,System.String)">
            <summary>
            Adds Ollama as the text embedding generation backend for semantic kernel
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <param name="serviceId"></param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaMemoryBuilderExtensions.WithOllamaTextEmbeddingGeneration(Microsoft.SemanticKernel.Memory.MemoryBuilder,System.String,System.String)">
            <summary>
            Adds Ollama as the text embedding generation backend for semantic memory
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <returns></returns>
        </member>
        <member name="M:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaMemoryBuilderExtensions.WithOllamaTextEmbeddingGeneration(Microsoft.SemanticKernel.Memory.MemoryBuilder,System.String,System.Uri)">
            <summary>
            Adds Ollama as the text embedding generation backend for semantic memory
            </summary>
            <param name="builder">kernel builder</param>
            <param name="modelId">Ollama model ID to use</param>
            <param name="baseUrl">Ollama base url</param>
            <returns></returns>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaPromptExecutionSettings.Temperature">
            <summary>
            Temperature controls the randomness of the completion.
            The higher the temperature, the more random the completion.
            Default is 1.0.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaPromptExecutionSettings.TopP">
            <summary>
            Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. 
            Default: 0.9
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaPromptExecutionSettings.TopK">
            <summary>
            Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. 
            Default: 40
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaPromptExecutionSettings.MaxTokens">
            <summary>
            Maximum number of tokens to predict when generating text. (Default: 128, -1 = infinite generation, -2 = fill context)
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.Model">
            <summary>
            The model used to generate the response.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.CreatedAt">
            <summary>
            The message created date.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.Done">
            <summary>
            Value indicating whether the message is done.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.TotalDuration">
            <summary>
            The time spent generating the response.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.LoadDuration">
            <summary>
            The time spent in nanoseconds loading the model.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.PromptEvalCount">
            <summary>
            The number of tokens in the prompt.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.PromptEvalDuration">
            <summary>
            The time spent in nanoseconds evaluating the prompt.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.EvalCount">
            <summary>
            The number of tokens the response.
            </summary>
        </member>
        <member name="P:Codeblaze.SemanticKernel.Connectors.Ollama.OllamaResponseMessage.EvalDuration">
            <summary>
            The time in nanoseconds spent generating the response.
            </summary>
        </member>
    </members>
</doc>
